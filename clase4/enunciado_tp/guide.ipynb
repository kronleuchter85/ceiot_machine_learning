{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolvemos los ejercicios de TP1 y TP2 usando árboles de decisión\n",
    "\n",
    "OBS: Completar las celdas vacías o las que están incompletas si se observa `____` es para que completen.\n",
    "\n",
    "## TP1 - Regresión de calidad de vino portugués \"Vinho Verde\"\n",
    "\n",
    "En el TP1 se trabajó con un dataset de vinos portugués \"Vinho Verde\" en la variante tinta. Se cuenta con variables fisicoquímicas (entradas) y un puntaje de clasificación de tipo de vino. El análisis lo hicimos en el TP1, aquí vamos a ir directamente a implementar el modelo.\n",
    "\n",
    "Por lo que primero leemos el dataset y preparamos todo, igual que en el TP1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el dataset\n",
    "wine_df = pd.____(\"____\")\n",
    "\n",
    "# Obtenemos a X e y.\n",
    "# Para X usamos todas las columnas menos el target\n",
    "X = wine_df[[\"____\"]]\n",
    "y = wine_df[\"____\"]\n",
    "\n",
    "print(f\"La forma de X es {X.____}\")\n",
    "print(f\"La forma de y es {y.____}\")\n",
    "\n",
    "# Separamos el dataset en training y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Como no hay una buena distribucion de valores entre las calidades de vino, usamos el argumento opcional \n",
    "# para que se mantenga la proporcion en los conjuntos de entrenamiento y testeo. \n",
    "X_train, X_test, y_train, y_test = train_test_split(____, ____, test_size=____, random_state=42, stratify=y)\n",
    "\n",
    "# Como estamos trabajando con arboles, no vamos a realizar ninguna normalización\n",
    "\n",
    "# Cargamos las metricas de evaluación que usamos en el TP1\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con el dataset leido y separado el entrenamiento y validación, podemos a realizar el entrenamiento.\n",
    "\n",
    "Antes de entrenar el modelo, vamos a realizar una busqueda de hiperparametros. Vamos a usar una validación cruzada de 5 folds y una busqueda de grilla.\n",
    "\n",
    "Para este caso vamos usar el podado de arboles, usando el coeficiente alpha (la busqueda tambien se podria haber hecho jugando con niveles del arbol o cantidad de muestra por hoja)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos a GridSearch de sklearn\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo base para buscar los hiperparametros\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Creamos el arbol\n",
    "reg_tree = ____(criterion='squared_error', splitter='best', \n",
    "                max_depth=None, min_samples_split=2, min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos la busqueda de grilla\n",
    "grid_wine = GridSearchCV(___,\n",
    "                         {\"ccp_alpha\": np.linspace(0, 100, 1001)},\n",
    "                         refit=True,\n",
    "                         cv=StratifiedKFold(n_splits=____, shuffle=True),\n",
    "                         scoring='neg_mean_absolute_error',\n",
    "                         n_jobs=-1)\n",
    "grid_wine.____(X_train,____)\n",
    "\n",
    "# El mejor valor de hiperparametros es:\n",
    "print(____.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con el mejor modelo elegido en nuestra búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_wine = ____.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya elegido el mejor modelo, vamos a entrenar y evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos al modelo\n",
    "best_tree_wine.fit(____)\n",
    "\n",
    "# Evaluamos el modelo\n",
    "y_pred = ____\n",
    "rsquare_tree = r2_score(____, y_pred)\n",
    "mae_tree = mean_absolute_error(____)\n",
    "\n",
    "print(f\"El mejor arbol tuvo un coeficiente ajuste igual a {rsquare_tree}\")\n",
    "print(f\"El mejor arbol tuvo un MAE de {mae_tree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando los modelos que realizaos:\n",
    "\n",
    "- Modelo de regresion lineal\n",
    "- Modelo de regresión multiple\n",
    "- Arbol de decisión\n",
    "\n",
    "Las metricas que obtuvimos son:\n",
    "\n",
    "| Modelo              | MAE  | R2   |\n",
    "|---------------------|------|------|\n",
    "| Regresión lineal    | ____ | ____ |\n",
    "| Regresión multiple  | ____ | ____ |\n",
    "| Arbol de decisión   | ____ | ____ |\n",
    "\n",
    "En función a estos resultados y complejidad de los modelos, discutir cual es el mejor modelo. Algo extra que se puede hacer si desean, es ver el árbol que se arma y determinar en los primeros niveles, que son las cualidades mas importantes del vino usando graphwiz (ver el notebook que hicimos en clase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP2 - Clasificación de usuarios en campaña de red social\n",
    "\n",
    "En el TP2 se trabajó con un dataset de publicidad que lanzó una campaña de publicidad en una red social. Se cuenta con datos de la persona tales como `genero`, `edad` y `salario estimado`. Además se registró si el usuario luego compró el producto que la publicidad hacía referencia.\n",
    "\n",
    "Por lo que primero leemos el dataset y preparamos todo, igual que en el TP2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el dataset\n",
    "social_df = ____.read_csv(\"____\")\n",
    "\n",
    "# Dropeamos la columna que identifica a los usuarios\n",
    "social_df.drop(columns=\"____\", inplace=True)\n",
    "\n",
    "# Generamos dummies para genero\n",
    "social_df = ____.get_dummies(____, columns=[\"Gender\"], drop_first=True)\n",
    "\n",
    "# Obtenemos a X e y.\n",
    "# Para X usamos todas las columnas menos el target\n",
    "X = social_df[[\"____\"]]\n",
    "y = social_df[\"____\"]\n",
    "\n",
    "print(f\"La forma de X es {X.____}\")\n",
    "print(f\"La forma de y es {y.____}\")\n",
    "\n",
    "# Separamos el dataset en training y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(____, ____, test_size=.3, \n",
    "                                                    random_state=42, stratify=y)\n",
    "\n",
    "# Como estamos trabajando con arboles, no vamos a realizar ninguna normalización\n",
    "\n",
    "# Cargamos las metricas de evaluación que usamos en el TP2\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, fbeta_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con el dataset leído y separado el entrenamiento y validación, podemos a realizar el entrenamiento.\n",
    "\n",
    "Antes de entrenar el modelo, vamos a realizar una búsqueda de hiperparametros. Vamos a usar una validación cruzada de 5 folds y una búsqueda de grilla.\n",
    "\n",
    "Para este caso vamos usar el podado de árboles, usando el coeficiente alpha (ccp_alpha). Además vamos a buscar el mejor criterio (Índice de Gini o Entropía)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo base para buscar los hiperparametros\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Creamos el arbol\n",
    "clas_tree = ____(splitter='best', max_depth=None, min_samples_split=2, \n",
    "                 min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos la busqueda de grilla, como no podemos usar f0.5, vamos a usar a f1\n",
    "grid_social = ____(clas_tree,\n",
    "                   {\"____\": np.linspace(0, 100, 1001),\n",
    "                    \"criterion\": [\"gini\", \"entropy\"]},\n",
    "                    refit=True,\n",
    "                    cv=StratifiedKFold(n_splits=____, shuffle=True),\n",
    "                    scoring='f1',\n",
    "                    n_jobs=-1)\n",
    "grid_social.____(X_train,y_train)\n",
    "\n",
    "# El mejor valor de hiperparametros es:\n",
    "print(grid_social.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con el mejor modelo elegido en nuestra búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_social = ____.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya elegido el mejor modelo, vamos a entrenar y evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos al modelo\n",
    "best_tree_social.____\n",
    "\n",
    "# Evaluamos el modelo\n",
    "y_pred = ____\n",
    "cm_tree = confusion_matrix(____)\n",
    "f0_5_tree = ____(____, ____, zero_division=0, beta=0.5)\n",
    "\n",
    "print(f\"El mejor arbol tuvo un f0.5 de {f0_5_tree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=____,\n",
    "                              display_labels=best_tree_social.classes_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.grid(False)\n",
    "disp.plot(ax=ax)\n",
    "ax.set_title(\"Clasificador arbol\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando los modelos que realizamos:\n",
    "\n",
    "- Modelo de regresión logística\n",
    "- Modelo kNN\n",
    "- Árbol de decisión\n",
    "\n",
    "Las métricas que obtuvimos son:\n",
    "\n",
    "| Modelo              | F0.5 | Precisión | Especificidad |\n",
    "|---------------------|------|-----------|---------------|\n",
    "| Regresión logistica | ____ |    ____   |      ____     |\n",
    "| kNN                 | ____ |    ____   |      ____     |\n",
    "| Arbol de decisión   | ____ |    ____   |      ____     |\n",
    "\n",
    "En función a estos resultados y complejidad de los modelos, discutir cual es el mejor modelo. Algo extra que se puede hacer si desean, es ver el árbol que se arma y determinar los perfiles de usuarios que compran los productos que se publicitan usando graphwiz (ver el notebook que hicimos en clase)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_env_python3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
